{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Helper_Functions.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMTQxwxUTFnX3N3lkZHuuY5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"lMlGXgTAH3XK","colab_type":"code","colab":{}},"source":["import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLp6ennGHntC","colab_type":"code","colab":{}},"source":["def sigmoid(z):\n","\n","    s = 1/(1+np.exp(-z))\n","    \n","    return s"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RJ6rJxdIxEf","colab_type":"code","colab":{}},"source":["def init(dimen):\n","  W=np.zeros([dimen,1])\n","  b=0\n","\n","  return W,b\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnDei3jQJxXU","colab_type":"code","colab":{}},"source":["def gradANDcost(W,b,X,y):\n","\n","  m=X.shape[1]\n","\n","  A=sigmoid(np.dot(W.T,X)+b)\n","  cost = (-1/m)*(np.dot(y,np.log(A).T)+np.dot((1-y),np.log(1-A).T))\n","\n","  dw=(1/m)*np.dot(X,(A-Y).T)\n","  db=(1/m)*np.sum(A-Y)\n","\n","  grads = {\"dw\":dw,\n","          \"db\":db}\n","  return grads ,cost        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXsqCxd0RAgn","colab_type":"code","colab":{}},"source":["def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n","    \n","    costs = []\n","    \n","    for i in range(num_iterations):\n","\n","        grads, cost = propagate(w,b,X,Y)\n"," \n","        dw = grads[\"dw\"]\n","        db = grads[\"db\"]\n","       \n","        w = w-learning_rate*dw\n","        b = b-learning_rate*db\n","\n","        if i % 100 == 0:\n","            costs.append(cost)\n","    \n","        if print_cost and i % 100 == 0:\n","            print (\"Cost after iteration %i: %f\" %(i, cost))\n","    \n","    params = {\"w\": w,\n","              \"b\": b}\n","    \n","    grads = {\"dw\": dw,\n","             \"db\": db}\n","    \n","    return params, grads, costs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fgxqu27uTAIP","colab_type":"code","colab":{}},"source":["def predict(W, b, X):\n","     \n","    m = X.shape[1]\n","    Y_prediction = np.zeros((1,m))\n","    W = W.reshape(X.shape[0], 1)\n","  \n","    A = sigmoid(np.dot(w.T,X)+b)\n","    \n","    for i in range(A.shape[1]):\n","        \n","        if(A[0][i] <= 0.5):\n","            Y_prediction[0][i] = 0\n","        else:\n","            Y_prediction[0][i] = 1\n","    \n","    assert(Y_prediction.shape == (1, m))\n","    \n","    return Y_prediction"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"91Ckm2Sc8iCs","colab_type":"code","colab":{}},"source":["def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5):\n","\n","    w, b = initialize_with_zeros(X_train.shape[0])\n","\n","   \n","    parameters, grads = gradANDcost(W, b, X_train, Y_train, num_iterations= 2000, learning_rate = 0.005)\n","    \n","    # Retrieve parameters w and b from dictionary \"parameters\"\n","    w = parameters[\"w\"]\n","    b = parameters[\"b\"]\n","    \n","    # Predict test/train set examples (â‰ˆ 2 lines of code)\n","    Y_prediction_test = predict(w, b, X_test)\n","    Y_prediction_train = predict(w, b, X_train)\n","\n","    ### END CODE HERE ###\n","\n","    # Print train/test Errors\n","    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n","    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n","\n","    \n","    d = {\"costs\": costs,\n","         \"Y_prediction_test\": Y_prediction_test, \n","         \"Y_prediction_train\" : Y_prediction_train, \n","         \"w\" : w, \n","         \"b\" : b,\n","         \"learning_rate\" : learning_rate,\n","         \"num_iterations\": num_iterations}\n","    \n","    return d"],"execution_count":0,"outputs":[]}]}